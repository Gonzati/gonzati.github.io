---
layout: post
title: "Predicci√≥n de costas judiciales con BigQuery ML"
date: 2025-11-18
---
![Portada del art√≠culo](/assets/images/portada-prediccion-costas.png)
Uno de los principales problemas de la litigaci√≥n masiva ‚Äîy tambi√©n de la no tan masiva‚Äî es **estimar con antelaci√≥n las costas que pueden generarse si se pierde un procedimiento**. La dificultad se ha agudizado en los √∫ltimos a√±os por el **abandono progresivo de los baremos tradicionales** utilizados en las tasaciones.

En esta entrada explico c√≥mo constru√≠ un **modelo de regresi√≥n en BigQuery ML**, c√≥mo dise√±√© una **canalizaci√≥n incremental en Dataform**, y c√≥mo gener√© un flujo completo que permite a un equipo de analistas **obtener predicciones actualizadas de manera autom√°tica**, usando solo SQL.

Todas las piezas del proyecto est√°n disponibles en este repositorio:  
üëâ https://github.com/Gonzati/prediccion_de_costas_pipeline_dataform

---

# üîç 1. ¬øEs posible predecir las costas judiciales?

La pregunta inicial fue doble:

- **¬øEs t√©cnicamente posible predecir las costas?**  
- **En caso afirmativo, ¬øpodemos sistematizar su predicci√≥n en un pipeline reproducible?**

La respuesta corta es: **s√≠**.

Existe una **relaci√≥n estad√≠sticamente muy fuerte entre la cuant√≠a reclamada y las costas generadas**. Esa correlaci√≥n permite utilizar un **modelo de regresi√≥n lineal sencillo**, sin necesidad de recurrir a AutoML, para alcanzar una precisi√≥n m√°s que razonable.

En esta demostraci√≥n utilic√© **datos sint√©ticos** (5.000 filas) generados √∫nicamente para documentar el procedimiento.

---

# üìä 2. El dataset de origen

El dataset consist√≠a en un CSV con las siguientes columnas:

- `CUANTIA`
- `COSTAS`
- `FECHA_SENTENCIA`
- `FECHA_COBRO`

Con estas variables es posible predecir:

1. **Cu√°nto** pagaremos de costas (modelo de regresi√≥n)
2. **Cu√°ndo** se producir√° la tasaci√≥n (aprox. 86 d√≠as tras la sentencia en la simulaci√≥n)

Tras subir el CSV al bucket de origen, cre√© un dataset en BigQuery llamado "Modelo_Costas", y la Tabla "Modelo_costas.datos"


---

# ü§ñ 3. Entrenamiento del modelo en BigQuery ML

No utilic√© AutoML porque ya conoc√≠a la relaci√≥n entre cuant√≠a y costas. Opt√© por un enfoque transparente:

```sql
CREATE OR REPLACE MODEL `Modelo_costas.modelo_costas_lr`
OPTIONS (
  model_type = 'linear_reg',
  input_label_cols = ['COSTAS'],
  data_split_method = 'RANDOM',
  data_split_eval_fraction = 0.20,
  category_encoding_method = 'DUMMY_ENCODING',
  calculate_p_values = TRUE
) AS
SELECT
  CUANTIA,
  COSTAS
FROM `Modelo_costas.datos`;

El modelo se entren√≥ correctamente, mostrando unas m√©tricas s√≥lidas y coherentes con el comportamiento esperado en datos reales.

Con esto ya ten√≠amos un modelo funcional y evaluado, accesible desde SQL mediante ML.PREDICT.

üîß 4. Una canalizaci√≥n SQL-first para analistas: Dataform

Imaginemos que distintos analistas deben generar predicciones continuamente sobre nuevos casos. Para ellos, lo ideal es una herramienta donde pudieran construir transformaciones usando exclusivamente SQL.

La respuesta natural es Dataform.

Constru√≠ un ejemplo de canalizaci√≥n incremental:
config {
  type: "incremental",
  name: "predicciones_detalle",
  database: "rag-vertex-477211",
  schema: "Modelo_costas",
  uniqueKey: ["row_id"],
  bigquery: {
    partitionBy: "DATE_TRUNC(FECHA_COBRO, MONTH)",
    clusterBy: ["FECHA_COBRO", "FECHA_SENTENCIA"]
  },
  tags: ["predict"]
}

WITH src AS (
  SELECT
    CUANTIA,
    FECHA_SENTENCIA
  FROM `rag-vertex-477211.Modelo_costas.nuevos_casos_ext`
  WHERE CUANTIA IS NOT NULL AND FECHA_SENTENCIA IS NOT NULL
),

pred AS (
  SELECT
    CUANTIA,
    FECHA_SENTENCIA,
    predicted_COSTAS
  FROM ML.PREDICT(
    MODEL `rag-vertex-477211.Modelo_costas.modelo_costas_lr`,
    TABLE src
  )
)

SELECT
  CAST(FARM_FINGERPRINT(CONCAT(CAST(CUANTIA AS STRING), '|', CAST(FECHA_SENTENCIA AS STRING))) AS INT64) AS row_id,
  ROUND(CUANTIA, 2) AS CUANTIA,
  FECHA_SENTENCIA,
  DATE_ADD(FECHA_SENTENCIA, INTERVAL 86 DAY) AS FECHA_COBRO,
  ROUND(LEAST(50000.0, GREATEST(1.0, predicted_COSTAS)), 2) AS COSTAS_PREDICHAS
FROM pred;
Este script:

- Calcula predicciones con ML.PREDICT

- Genera un identificador √∫nico por fila

- Calcula una fecha estimada de cobro

- Limita valores extremos

- Inserta solo nuevas filas mediante incremental

üìà 5. Visualizaci√≥n en Looker Studio

Una vez creada la tabla de predicciones en BigQuery, solo quedaba conectarla a Looker Studio.

El resultado era un dashboard sencillo pero funcional, donde se pod√≠an analizar:

Cuant√≠as

Fechas de sentencia

Predicciones de costas

Tendencias por mes de cobro

Ideal para analistas acostumbrados a consumir datos de manera visual.

üß© 6. Resultado: un pipeline end-to-end simple y eficaz

Con muy pocas herramientas:

BigQuery ML

Dataform

Looker Studio

‚Ä¶se puede construir una soluci√≥n autom√°tica y escalable que permita predecir costes futuros de litigaci√≥n y alimentar decisiones de negocio sin necesidad de herramientas externas ni Python.

El valor clave de este enfoque es que todo se ejecuta con SQL, lo que permite que equipos no familiarizados con frameworks complejos puedan operar, mantener y extender la soluci√≥n.

En futuras entradas documentar√© variantes del modelo, el uso de otras features y la integraci√≥n con canalizaciones orquestadas mediante Composer.

