---
layout: post
title: "Clustering K-Means en Excel: aprendizaje no supervisado sin librer√≠as externas"
date: 2025-12-16
author: "√Ångel Argibay"
tags: [Excel, VBA, K-Means, Clustering, Machine Learning, Data Engineering]
---

<p align="center">
  <img src="/assets/images/portada-kmeans-excel.png" alt="Portada del art√≠culo" style="max-width: 800px; width: 100%; border-radius: 6px;">
</p>

<style>
.post-content p {
  text-align: justify;
}
.post-content li {
  text-align: justify;
}
</style>

> **Resumen r√°pido:**  
> En esta entrada implemento el algoritmo **K-Means** directamente en Excel usando **VBA**, aplic√°ndolo sobre datos en formato *one-hot encoding*. Adem√°s, utilizo la **t√©cnica del codo** para justificar el n√∫mero √≥ptimo de clusters. Todo el proceso es transparente, reproducible y sin usar Python, R ni librer√≠as externas.

---

# üß© Introducci√≥n

Antes de entrar en la implementaci√≥n pr√°ctica, conviene detenerse un momento en **qu√© es realmente K-Means y c√≥mo funciona internamente**, m√°s all√° de la definici√≥n habitual.

**K-Means** es uno de los algoritmos m√°s conocidos de **aprendizaje no supervisado** y se utiliza cuando:

- no existen etiquetas previas,  
- queremos descubrir patrones,  
- o necesitamos segmentar datos de forma autom√°tica.  

Su objetivo es sencillo de formular, pero interesante desde el punto de vista matem√°tico:

> Agrupar observaciones en **K clusters** de forma que los elementos dentro de cada cluster sean lo m√°s similares posible entre s√≠, y lo m√°s distintos posible de los de otros clusters.

---

## üîç La intuici√≥n detr√°s de K-Means

El algoritmo parte de una idea muy simple:

1. Elegimos un n√∫mero **K** de grupos.  
2. Colocamos **K puntos iniciales** llamados *centroides*.  
3. Cada observaci√≥n se asigna al centro m√°s cercano.  
4. Cada centro se mueve a la **media** de los puntos que tiene asignados.  
5. Repetimos el proceso hasta que los centros dejan de moverse.  

Aunque parezca trivial, este mecanismo iterativo genera estructuras sorprendentemente coherentes incluso en datasets complejos.

---

## üîÅ K-Means como proceso iterativo

Una de las claves para entender K-Means es que **no encuentra la soluci√≥n de una sola vez**.  
Funciona por **aproximaciones sucesivas**:

- primero asigna,  
- luego corrige,  
- luego vuelve a asignar,  
- y as√≠ hasta converger.  

Este comportamiento se aprecia muy bien en la siguiente animaci√≥n, donde se observa c√≥mo los centroides se desplazan y c√≥mo cambian las asignaciones en cada iteraci√≥n:

<p align="center">
  <img src="/assets/images/K-means_convergence.gif" alt="Convergencia del algoritmo K-Means" style="max-width: 700px; width: 100%; border-radius: 6px;">
</p>

<p align="center">
  <em>
    By Chire - Own work, CC BY-SA 4.0,  
    <a href="https://commons.wikimedia.org/w/index.php?curid=59409335" target="_blank">
      https://commons.wikimedia.org/w/index.php?curid=59409335
    </a>
  </em>
</p>

En cada iteraci√≥n ocurre lo siguiente:

- los puntos se reasignan al centro m√°s cercano,  
- los centros se recalculan como la media de sus puntos,  
- las fronteras entre clusters se reajustan.  

El proceso contin√∫a hasta que las asignaciones dejan de cambiar o el movimiento de los centroides es despreciable.

---

## üìê El criterio matem√°tico

Formalmente, K-Means intenta **minimizar la dispersi√≥n dentro de cada cluster**, lo que en la pr√°ctica equivale a minimizar la suma de las distancias cuadr√°ticas de cada punto a su centroide.

Esta m√©trica es conocida como **SSE (Sum of Squared Errors)** y ser√° clave m√°s adelante cuando apliquemos la **t√©cnica del codo** para elegir el n√∫mero √≥ptimo de clusters.

Dicho formalmente, el algoritmo busca minimizar la siguiente expresi√≥n:

SSE = Œ£·µ¢ Œ£‚Çì‚ààC·µ¢ || x ‚àí Œº·µ¢ ||¬≤

donde:

- **K** es el n√∫mero de clusters
- **C·µ¢** es el conjunto de puntos asignados al cluster *i*
- **x** es una observaci√≥n
- **Œº·µ¢** es el centroide (media) del cluster *i*
- **|| x ‚àí Œº·µ¢ ||¬≤** es la distancia eucl√≠dea al cuadrado

Esta magnitud, conocida como **SSE (Sum of Squared Errors)**, es la que se representa en la t√©cnica del codo para justificar el n√∫mero √≥ptimo de clusters.
---

# üîç ¬øQu√© problema resolvemos?

El objetivo es agrupar observaciones en funci√≥n de sus caracter√≠sticas, sin conocer previamente la categor√≠a a la que pertenecen.

En el caso pr√°ctico del repositorio:

- cada fila representa una observaci√≥n (por ejemplo, una sentencia, un documento o un registro),  
- cada columna representa una caracter√≠stica binaria (*one-hot encoding*), que en este caso son los motivos tratados en la sentencia, si representamos a demandante o demandado, y si la sentencia es favorable o desfavorable.  
- el algoritmo debe agrupar las filas en clusters coherentes seg√∫n sus patrones.  

El enfoque es totalmente generalizable a cualquier otro dominio.

---

# üß± Implementaci√≥n en Excel + VBA

La implementaci√≥n se apoya en tres bloques fundamentales:

### ‚úî Datos de entrada
- Matriz de datos (filas = observaciones, columnas = variables).  
- Normalmente en formato **one-hot encoding (0/1)**.

### ‚úî Centroides
- Una fila por cluster.  
- Se inicializan manualmente o de forma arbitraria.  
- Se recalculan autom√°ticamente en cada iteraci√≥n.

### ‚úî Asignaci√≥n de clusters
- Una columna donde Excel escribe `C1`, `C2`, `C3`, etc.  
- Representa el cluster asignado a cada observaci√≥n.

Todo el c√°lculo de distancias se hace mediante **distancia eucl√≠dea**, exactamente igual que en implementaciones est√°ndar.

---

# üîÅ El algoritmo paso a paso (VBA)

El flujo interno del c√≥digo es el siguiente:

1. Leer el rango de datos y el rango de centroides.  
2. Para cada fila:
   - calcular la distancia a cada centro,  
   - asignar el cluster m√°s cercano.  
3. Comprobar si alguna asignaci√≥n ha cambiado.  
4. Recalcular los centroides usando medias.  
5. Repetir hasta convergencia o m√°ximo de iteraciones.  

El n√∫mero de clusters **no est√° hardcodeado**:  
se deduce autom√°ticamente del n√∫mero de filas del rango de centroides.

Esto permite probar distintos valores de **K** sin modificar el c√≥digo.

---

# üìê La t√©cnica del codo en Excel

Elegir **K** ‚Äúa ojo‚Äù no es una buena pr√°ctica.  
Para justificar el n√∫mero de clusters se aplica la **t√©cnica del codo**.

El proceso es el siguiente:

1. Ejecutar K-Means para distintos valores de K (por ejemplo, de 1 a 10).  
2. Para cada K, calcular la **SSE (Sum of Squared Errors)**.  
3. Representar SSE frente a K en un gr√°fico.  
4. Identificar el punto donde la mejora empieza a ser marginal: el ‚Äúcodo‚Äù.  

Todo este proceso se realiza **dentro de Excel**, sin c√°lculos externos.

As√≠, una vez ejecutado el c√≥digo, obtendremos la visualizaci√≥n correspondiente:

<p align="center">
  <img src="/assets/images/codo.png" alt="Visualizaci√≥n del codo" style="max-width: 800px; width: 100%; border-radius: 6px;">
</p>

<style>
.post-content p {
  text-align: justify;
}
.post-content li {
  text-align: justify;
}
</style>

En la imagen podemos observar que el n√∫mero √≥ptimo de cl√∫sters se encuentra entre 5 y 6.

# üìä Aplicando K-Means sobre el dataset

Una vez que ejecutamos el c√≥digo del m√≥dulo "clustering.bas" veremos que es le asigna un cl√∫ster a cada fila, en la columna "cl√∫ster":
<p align="center">
  <img src="/assets/images/dataset.png" alt="Asignaci√≥n de cluster" style="max-width: 800px; width: 100%; border-radius: 6px;">
</p>

<style>
.post-content p {
  text-align: justify;
}
.post-content li {
  text-align: justify;
}
</style>

Y ya, con esta tabla creada, podemos visualizar la composici√≥n de los cl√∫sters, lo cual nos permite detectar a simple vista patrones, si estos existiesen:

<p align="center">
  <img src="/assets/images/clusters.png" alt="Visualizaci√≥n de los clusters" style="max-width: 800px; width: 100%; border-radius: 6px;">
</p>

<style>
.post-content p {
  text-align: justify;
}
.post-content li {
  text-align: justify;
}
</style>

Esto resulta especialmente √∫til en contextos exploratorios, donde el objetivo no es predecir, sino **entender la estructura interna de los datos** antes de tomar decisiones posteriores.

---

# üñ•Ô∏è Transparencia total (sin caja negra)

Una de las mayores ventajas de esta aproximaci√≥n es que:

- puedes ver cada distancia calculada,  
- puedes inspeccionar cada centro,  
- puedes seguir cada iteraci√≥n,  
- puedes validar manualmente los resultados.  

Esto convierte el proyecto en una herramienta **did√°ctica**, pero tambi√©n en una soluci√≥n perfectamente v√°lida para producci√≥n en entornos limitados.

---

# üß∞ ¬øQu√© aporta este proyecto?

‚úî Implementaci√≥n real de K-Means desde cero  
‚úî Comprensi√≥n profunda del algoritmo  
‚úî Aplicable en entornos corporativos restrictivos  
‚úî Justificaci√≥n matem√°tica del n√∫mero de clusters  
‚úî Reproducible, auditable y modificable  
‚úî 100% Excel + VBA  

---

# üß≠ Limitaciones del enfoque

Como cualquier implementaci√≥n de K-Means, este enfoque tiene algunas limitaciones:

- es sensible a la inicializaci√≥n de los centroides  
- requiere fijar K a priori  
- funciona mejor con variables num√©ricas homog√©neas  

Aun as√≠, para an√°lisis exploratorios y entornos restringidos, ofrece un equilibrio muy s√≥lido entre interpretabilidad y utilidad pr√°ctica.

---

# üöÄ Conclusi√≥n

Este proyecto no pretende competir con scikit-learn ni con Spark.

Pretende algo distinto y, en muchos contextos, m√°s valioso:  
**entender realmente qu√© est√° pasando cuando hacemos clustering**.

Implementar K-Means en Excel obliga a pensar en cada paso, cada c√°lculo y cada decisi√≥n.  
Y eso, a largo plazo, es lo que marca la diferencia entre *usar* modelos y *comprenderlos*.

Puedes encontrar todo el material, los libros de Excel y el c√≥digo VBA en el repositorio:

[üîó Repositorio del proyecto](https://github.com/Gonzati/clustering-kmeans-excel)

---
